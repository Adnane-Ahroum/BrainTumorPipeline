{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adnane-Ahroum/BrainTumorPipeline/blob/main/classificationfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHZ8ACui9ncy"
      },
      "source": [
        "# Brain Tumor Classification\n",
        "\n",
        "This notebook has been modified to:\n",
        "1. Add Weights & Biases (wandb) integration for experiment tracking\n",
        "2. Properly load MATLAB data files from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d67pYnXv9ncz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import scipy.io as sio\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torch.optim import Adam\n",
        "from torchvision.models import densenet121\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLTWRinc9nc0"
      },
      "source": [
        "## Data Loading - Fixed to work with repository files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8lfhjtV9nc0"
      },
      "outputs": [],
      "source": [
        "def load_matlab_data(file_path):\n",
        "    \"\"\"Load data from a MATLAB .mat file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the .mat file.\n",
        "    Returns:\n",
        "        images: Numpy array of images\n",
        "        labels: Numpy array of labels\n",
        "    \"\"\"\n",
        "    # Make sure the file_path has .mat extension\n",
        "    if not file_path.endswith('.mat'):\n",
        "        file_path = file_path + '.mat'\n",
        "\n",
        "    # Verify that the file exists\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"MATLAB file not found: {file_path}\")\n",
        "\n",
        "    mat_data = sio.loadmat(file_path)\n",
        "\n",
        "    # Print available keys to debug\n",
        "    print(f\"Available keys in {file_path}: {list(mat_data.keys())}\")\n",
        "\n",
        "    # Common keys in MATLAB files - try different possibilities\n",
        "    possible_image_keys = ['images', 'image', 'Images', 'Image', 'data', 'Data', 'X', 'features']\n",
        "    possible_label_keys = ['labels', 'label', 'Labels', 'Label', 'y', 'classes', 'Categories']\n",
        "\n",
        "    # Try to find image data\n",
        "    images = None\n",
        "    for key in possible_image_keys:\n",
        "        if key in mat_data:\n",
        "            images = mat_data[key]\n",
        "            print(f\"Found images under key: {key}\")\n",
        "            break\n",
        "\n",
        "    # Try to find label data\n",
        "    labels = None\n",
        "    for key in possible_label_keys:\n",
        "        if key in mat_data:\n",
        "            labels = mat_data[key]\n",
        "            print(f\"Found labels under key: {key}\")\n",
        "            break\n",
        "\n",
        "    if images is None or labels is None:\n",
        "        raise ValueError(\"Could not find image or label data in the MATLAB file\")\n",
        "\n",
        "    # Handle potential dimensionality issues\n",
        "    if labels.ndim > 1 and labels.shape[1] > 1:\n",
        "        print(\"Warning: Labels have multiple columns, using first column\")\n",
        "        labels = labels[:, 0]\n",
        "\n",
        "    return images, labels.ravel()  # Ensure labels are flattened"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb project\n",
        "wandb.init(\n",
        "    project=\"brain-tumor-classification\",\n",
        "    name=\"classification-experiment\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"epochs\": 30,\n",
        "        \"batch_size\": 16,\n",
        "        \"model\": \"DenseNet121\",\n",
        "        \"dataset\": \"Brain Tumor Dataset\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "P1nGuZ6nDQQB",
        "outputId": "f7c8339e-580b-473b-d7b7-dbe6b6316fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madnaneahroum69\u001b[0m (\u001b[33madnaneahroum69-al-akhawayn-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250426_011614-0epp6qqs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification/runs/0epp6qqs' target=\"_blank\">classification-experiment</a></strong> to <a href='https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification' target=\"_blank\">https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification/runs/0epp6qqs' target=\"_blank\">https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification/runs/0epp6qqs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/adnaneahroum69-al-akhawayn-university/brain-tumor-classification/runs/0epp6qqs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x780b9a59c650>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlI4hlQyT4u_",
        "outputId": "57649cb9-6daf-4f15-dfb4-10af9c55f2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = '/content/drive/MyDrive/DATASETCLASSIFICATION/Training'\n",
        "test_dir  = '/content/drive/MyDrive/DATASETCLASSIFICATION/Testing'\n"
      ],
      "metadata": {
        "id": "nBAYtm01XPvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE DATA FROM MATLAB FILES\n"
      ],
      "metadata": {
        "id": "uHdNRZ5nEWJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mat73"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOyCvbBSEOZi",
        "outputId": "fd873cfd-e708-45f2-fbc5-72bc34b9787f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mat73\n",
            "  Downloading mat73-0.65-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from mat73) (3.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mat73) (2.0.2)\n",
            "Downloading mat73-0.65-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: mat73\n",
            "Successfully installed mat73-0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Optional: install mat73 (pip install mat73) for v7.3 files\n",
        "import mat73\n",
        "\n",
        "# Define tumor classes and labels\n",
        "CLASSES = ['glioma', 'pituitary', 'meningioma']\n",
        "CLASS_TO_LABEL = {cls: idx for idx, cls in enumerate(CLASSES)}\n",
        "\n",
        "def load_mat_data(path, data_key='cjdata'):\n",
        "    \"\"\"Load a single .mat file, using scipy for <=7.2 or mat73 for v7.3.\"\"\"\n",
        "    try:\n",
        "        mat = sio.loadmat(path)\n",
        "        if data_key in mat:\n",
        "            return mat[data_key]\n",
        "        raise KeyError(f\"Key '{data_key}' not found in {path}\")\n",
        "    except NotImplementedError:\n",
        "        # v7.3 file, fallback to mat73\n",
        "        mat = mat73.loadmat(path)\n",
        "        if data_key in mat:\n",
        "            return mat[data_key]\n",
        "        raise KeyError(f\"Key '{data_key}' not found in {path} (v7.3)\")\n",
        "\n",
        "\n",
        "def load_data_for_three_tumors(root_dir, data_key='cjdata'):\n",
        "    \"\"\"Load images and labels for three tumor classes from subfolders.\"\"\"\n",
        "    images, labels = [], []\n",
        "    for cls in CLASSES:\n",
        "        subfolder = os.path.join(root_dir, cls)\n",
        "        if not os.path.isdir(subfolder):\n",
        "            raise FileNotFoundError(f\"Missing folder: {subfolder}\")\n",
        "        for fname in os.listdir(subfolder):\n",
        "            if not fname.endswith('.mat'): continue\n",
        "            path = os.path.join(subfolder, fname)\n",
        "            try:\n",
        "                img = load_mat_data(path, data_key)\n",
        "                images.append(img)\n",
        "                labels.append(CLASS_TO_LABEL[cls])\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {fname}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Usage in Colab after extracting dataset.zip\n",
        "train_dir = '/content/drive/MyDrive/DATASETCLASSIFICATION/Training'\n",
        "test_dir  = '/content/drive/MyDrive/DATASETCLASSIFICATION/Testing'\n",
        "\n",
        "X_train, y_train = load_data_for_three_tumors(train_dir)\n",
        "print(f\"Training: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "\n",
        "X_test, y_test = load_data_for_three_tumors(test_dir)\n",
        "print(f\"Testing:  {X_test.shape}, Labels: {y_test.shape}\")\n",
        "\n",
        "# Split train into train/val\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "print(f\"After split → Train: {X_train.shape}, Val: {X_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNcIJhuDgai",
        "outputId": "c421d42e-eb6b-481e-e348-03a1aa0281dc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: (2452,), Labels: (2452,)\n",
            "Testing:  (612,), Labels: (612,)\n",
            "After split → Train: (1961,), Val: (491,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Ensure the image is in the correct format (RGB, normalized, etc.)\n",
        "        # This depends on your data format\n",
        "        if image.ndim == 2:  # Convert grayscale to RGB if needed\n",
        "            image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        # Convert to PIL Image for transformations\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = BrainTumorDataset(X_train, y_train, transform=train_transform)\n",
        "val_dataset = BrainTumorDataset(X_val, y_val, transform=val_transform)\n",
        "\n",
        "batch_size = wandb.config.batch_size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "DJ6YD84Tm12r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wJt4UiwvnFke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL DEFINITION\n"
      ],
      "metadata": {
        "id": "mdbdNPCMDhbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        # Debug info\n",
        "        print(f\"Dataset initialized with {len(images)} samples\")\n",
        "        print(f\"Image type: {type(images)} with shape {images.shape if hasattr(images, 'shape') else 'unknown'}\")\n",
        "        if len(images) > 0:\n",
        "            print(f\"First image type: {type(images[0])}\")\n",
        "            if hasattr(images[0], 'shape'):\n",
        "                print(f\"First image shape: {images[0].shape}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # If image is a dictionary or a complex structure\n",
        "        if isinstance(image, (dict, np.void)):\n",
        "            # For numpy structured arrays\n",
        "            if hasattr(image, 'dtype') and image.dtype.names:\n",
        "                for field in ['image', 'data', 'img', 'Signal', 'pixels']:\n",
        "                    if field in image.dtype.names:\n",
        "                        image = image[field]\n",
        "                        break\n",
        "                else:\n",
        "                    # Use first field that has array-like data\n",
        "                    for field in image.dtype.names:\n",
        "                        if hasattr(image[field], 'shape'):\n",
        "                            image = image[field]\n",
        "                            break\n",
        "            elif isinstance(image, dict):\n",
        "                # For dictionary structures\n",
        "                for field in ['image', 'data', 'img', 'Signal', 'pixels']:\n",
        "                    if field in image:\n",
        "                        image = image[field]\n",
        "                        break\n",
        "                else:\n",
        "                    # Use first value that has array-like data\n",
        "                    for value in image.values():\n",
        "                        if hasattr(value, 'shape'):\n",
        "                            image = value\n",
        "                            break\n",
        "\n",
        "        # Convert to numpy array if it's not already\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            try:\n",
        "                image = np.array(image)\n",
        "            except:\n",
        "                # Create a blank image if conversion fails\n",
        "                image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "        # Handle dimensionality\n",
        "        if image.ndim == 2:  # Convert grayscale to RGB\n",
        "            image = np.stack([image] * 3, axis=-1)\n",
        "        elif image.ndim == 3 and image.shape[2] == 1:  # Handle single channel\n",
        "            image = np.concatenate([image] * 3, axis=2)\n",
        "        elif image.ndim > 3:  # Handle multi-dimensional data\n",
        "            # Take the first 3D volume or middle slice\n",
        "            if image.shape[0] > 0:\n",
        "                image = image[image.shape[0]//2] if image.ndim == 4 else image[0]\n",
        "                # If still 3D with depth, take middle slice\n",
        "                if image.ndim == 3 and not (image.shape[2] == 3 or image.shape[2] == 1):\n",
        "                    image = image[:, :, image.shape[2]//2]\n",
        "                # Convert to RGB\n",
        "                if image.ndim == 2:\n",
        "                    image = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "        # Normalize and convert to uint8\n",
        "        if image.dtype != np.uint8:\n",
        "            if image.max() <= 1.0:\n",
        "                image = (image * 255).astype(np.uint8)\n",
        "            else:\n",
        "                image = np.clip(image, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Make sure shape is correct for RGB\n",
        "        if image.shape[2] != 3:\n",
        "            # Handle unexpected channels\n",
        "            if image.ndim == 3:\n",
        "                if image.shape[2] > 3:\n",
        "                    image = image[:, :, :3]  # Take first 3 channels\n",
        "                else:\n",
        "                    # Duplicate last channel\n",
        "                    while image.shape[2] < 3:\n",
        "                        image = np.concatenate([image, image[:, :, -1:]], axis=2)\n",
        "\n",
        "        # Convert to PIL Image for transformations\n",
        "        try:\n",
        "            image = Image.fromarray(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting to PIL: {e}\")\n",
        "            image = Image.new('RGB', (224, 224), color='black')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "juhj4QIADc5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Function with wandb Integration"
      ],
      "metadata": {
        "id": "RAh_i05wnB_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss = val_loss / val_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc,\n",
        "            'confusion_matrix': wandb.Image(plt)\n",
        "        })\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_brain_tumor_classifier.pth')\n",
        "            wandb.save('best_brain_tumor_classifier.pth')\n",
        "            print(f\"Saved best model with validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "K1MYCBWBm_kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRAIN THE MODEL"
      ],
      "metadata": {
        "id": "T2kBc_kdnRkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "num_epochs = wandb.config.epochs\n",
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cXllw5W6nNKg",
        "outputId": "53afd472-930e-43b0-89dd-8ab6e12a28f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30:   0%|          | 0/123 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'ndim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b34bb6239714>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-71abb01215e1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6930d85ea070>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Ensure the image is in the correct format (RGB, normalized, etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# This depends on your data format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Convert grayscale to RGB if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ndim'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATE THEMODEL"
      ],
      "metadata": {
        "id": "4F3hq4UmnUf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_brain_tumor_classifier.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on validation set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate and display metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "class_report = classification_report(all_labels, all_preds)\n",
        "conf_mat = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Final Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Log final metrics to wandb\n",
        "wandb.log({\n",
        "    'final_accuracy': accuracy,\n",
        "    'final_confusion_matrix': wandb.Image(plt),\n",
        "    'classification_report': wandb.Table(\n",
        "        columns=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"],\n",
        "        data=[[i, *list(row.values())] for i, row in pd.DataFrame(classification_report(all_labels, all_preds, output_dict=True)).T.iterrows()]\n",
        "    )\n",
        "})\n",
        "\n",
        "# Finish the wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "_QdQp3XJnXJL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}